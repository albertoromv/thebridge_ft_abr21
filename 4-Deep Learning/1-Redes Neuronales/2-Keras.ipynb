{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPor defecto, keras tira de GPU\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras\n",
    "'''\n",
    "Por defecto, keras tira de GPU\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_train --> 60 000 fotos, cada una tiene 28x28 pixels   y_train --> 60 000 etiquetas\\n\\nfoto_0 -------> 0\\nfoto_1 -------> 0\\nfoto_2 -------> 0\\nfoto_3 -------> 1\\nfoto_4 -------> 1\\nfoto_5 -------> 3\\n\\n\\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X_train --> 60 000 fotos, cada una tiene 28x28 pixels   y_train --> 60 000 etiquetas\n",
    "\n",
    "foto_0 -------> 0\n",
    "foto_1 -------> 0\n",
    "foto_2 -------> 0\n",
    "foto_3 -------> 1\n",
    "foto_4 -------> 1\n",
    "foto_5 -------> 3\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x220b87c12e0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data (these are NumPy arrays). Aplano a una dimension cada imagen.\n",
    "# Escalamos ya que vamos a usar gradient descent, y le afecta mucho la escala de las features.\n",
    "# Ejecutar esta celda solo una vez. Si no, reescalará\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Reserve 10,000 samples for validation. Entraran dentro del modelo para validar. No es validacion cruzada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una manera de declarar la red neuronal\n",
    "\n",
    "# Siempre hay que declarar la capa sequential para empezar a declarar la red\n",
    "# Se trata de la API sequential\n",
    "\n",
    "\n",
    "# Flatten, aplana en un unico vector. Y especificamos el tamaño de la entrada\n",
    "# Es como si hiciese un .reshape(-1, 28*28)\n",
    "# \"kernel_initializer\" o \"bias_initializer\" No lo usamos pero seria para inicializar los pesos de otra manera\n",
    "\n",
    "\n",
    "# Capas de la red. Dense es la capa de neuronas. Necesitamos numero y activacion\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Capa de salida, con tamaño del número de clases\n",
    "# Suele ir aqui un softmax. Para multiclase guay. Si es binaria -> sigmoide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.dense.Dense object at 0x00000220B71D3B80>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x220b713f6d0>,\n",
       " <keras.layers.core.dense.Dense at 0x220b71d3b80>,\n",
       " <keras.layers.core.dense.Dense at 0x220b71d3a30>,\n",
       " <keras.layers.core.dense.Dense at 0x220b71d3c70>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 784 features (pixeles de las imagenes) x 300 neuronas\n",
    "# Los pesos están inicializados aleatoriamente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se especifica la configuración del entrenamiento (optimizador, pérdida, métricas):\n",
    "\n",
    "    # Stocastic gradient descent. El algoritmo para minimizar la loss function\n",
    "    # El stocastic va haciendo muestreo en cada evaluacion, no usa todo.\n",
    "    # Podemos modificar el learning rate(0.01 por defecto) mediante el parametro lr\n",
    "\n",
    "    \n",
    "    \n",
    "    # Loss function to minimize\n",
    "    # sparse_categorical_crossentropy cuando tenemos un label en nuna columna\n",
    "    # Si lo tuviesemos en varias tipo dummy, cogeriamos categorical_crossentropy\n",
    "\n",
    "    \n",
    "    \n",
    "    # List of metrics to monitor\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "# La primera hidden layer tiene 784 entradas x 300 salidas\n",
    "# Son los 235500 params = 783x300 + 300 (bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/15\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.8561 - accuracy: 0.7928 - val_loss: 0.3901 - val_accuracy: 0.8994\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.3782 - accuracy: 0.8962 - val_loss: 0.3133 - val_accuracy: 0.9128\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.3156 - accuracy: 0.9098 - val_loss: 0.2684 - val_accuracy: 0.9260\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.2807 - accuracy: 0.9197 - val_loss: 0.2439 - val_accuracy: 0.9318\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.2556 - accuracy: 0.9268 - val_loss: 0.2252 - val_accuracy: 0.9375\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2350 - accuracy: 0.9328 - val_loss: 0.2128 - val_accuracy: 0.9408\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.2181 - accuracy: 0.9384 - val_loss: 0.1989 - val_accuracy: 0.9459\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.2032 - accuracy: 0.9417 - val_loss: 0.1862 - val_accuracy: 0.9485\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.1902 - accuracy: 0.9456 - val_loss: 0.1754 - val_accuracy: 0.9527\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.1786 - accuracy: 0.9489 - val_loss: 0.1767 - val_accuracy: 0.9517\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.1681 - accuracy: 0.9518 - val_loss: 0.1618 - val_accuracy: 0.9555\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.1589 - accuracy: 0.9544 - val_loss: 0.1528 - val_accuracy: 0.9572\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1505 - accuracy: 0.9565 - val_loss: 0.1494 - val_accuracy: 0.9586\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1429 - accuracy: 0.9589 - val_loss: 0.1419 - val_accuracy: 0.9603\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1359 - accuracy: 0.9611 - val_loss: 0.1369 - val_accuracy: 0.9605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEn el entreanamiento solo hay que fijarse que el loss va para abajo, es bueno.\\nSi vemos que ya no baja mas, no serán necesarias tantas epochs.\\nImprimera tantas lineas como epochs hayamos puesto\\n\\nTampoco usamos el class_weight, que le da más peso a las clases con pocas muestras\\nUtil para datasets desbalanceados.\\n\\nEl loss que muestra es el categoricalcrossentropy\\n'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos el modelo con un batch_size de 64 imágenes por cada iteración, 10 epochs y especificando cuál es el conjunto de validación.\n",
    "\n",
    "\n",
    "'''\n",
    "En el entreanamiento solo hay que fijarse que el loss va para abajo, es bueno.\n",
    "Si vemos que ya no baja mas, no serán necesarias tantas epochs.\n",
    "Imprimera tantas lineas como epochs hayamos puesto\n",
    "\n",
    "Tampoco usamos el class_weight, que le da más peso a las clases con pocas muestras\n",
    "Util para datasets desbalanceados.\n",
    "\n",
    "El loss que muestra es el categoricalcrossentropy\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    # En vez de validation data podemos usar el argumento validation_split=0.1\n",
    "    \n",
    "\n",
    "'''\n",
    "En el entreanamiento solo hay que fijarse que el loss va para abajo, es bueno.\n",
    "Si vemos que ya no baja mas, no serán necesarias tantas epochs.\n",
    "Imprimera tantas lineas como epochs hayamos puesto\n",
    "\n",
    "Tampoco usamos el class_weight, que le da más peso a las clases con pocas muestras\n",
    "Util para datasets desbalanceados.\n",
    "\n",
    "El loss que muestra es el categoricalcrossentropy\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1293 - accuracy: 0.9635 - val_loss: 0.1316 - val_accuracy: 0.9629\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1232 - accuracy: 0.9652 - val_loss: 0.1281 - val_accuracy: 0.9638\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.1178 - accuracy: 0.9664 - val_loss: 0.1244 - val_accuracy: 0.9659\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.1124 - accuracy: 0.9680 - val_loss: 0.1222 - val_accuracy: 0.9658\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1077 - accuracy: 0.9691 - val_loss: 0.1174 - val_accuracy: 0.9673\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.1031 - accuracy: 0.9712 - val_loss: 0.1134 - val_accuracy: 0.9683\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.0987 - accuracy: 0.9723 - val_loss: 0.1134 - val_accuracy: 0.9697\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0951 - accuracy: 0.9728 - val_loss: 0.1107 - val_accuracy: 0.9689\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0911 - accuracy: 0.9745 - val_loss: 0.1083 - val_accuracy: 0.9685\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0875 - accuracy: 0.9753 - val_loss: 0.1064 - val_accuracy: 0.9707\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0844 - accuracy: 0.9761 - val_loss: 0.1067 - val_accuracy: 0.9703\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.0812 - accuracy: 0.9775 - val_loss: 0.1049 - val_accuracy: 0.9691\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0781 - accuracy: 0.9785 - val_loss: 0.1013 - val_accuracy: 0.9721\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.0756 - accuracy: 0.9788 - val_loss: 0.0995 - val_accuracy: 0.9716\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.0729 - accuracy: 0.9798 - val_loss: 0.0969 - val_accuracy: 0.9717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220b88ae9a0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 15, 'steps': 782}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.8560893535614014,\n",
       "  0.37823277711868286,\n",
       "  0.31557387113571167,\n",
       "  0.28070268034935,\n",
       "  0.2556193470954895,\n",
       "  0.23501455783843994,\n",
       "  0.21806283295154572,\n",
       "  0.20318157970905304,\n",
       "  0.19024457037448883,\n",
       "  0.17856290936470032,\n",
       "  0.1680687516927719,\n",
       "  0.15891902148723602,\n",
       "  0.15054933726787567,\n",
       "  0.14285583794116974,\n",
       "  0.13586768507957458],\n",
       " 'accuracy': [0.7928199768066406,\n",
       "  0.8962399959564209,\n",
       "  0.909820020198822,\n",
       "  0.9196799993515015,\n",
       "  0.9267799854278564,\n",
       "  0.9327600002288818,\n",
       "  0.9383999705314636,\n",
       "  0.9417399764060974,\n",
       "  0.9455999732017517,\n",
       "  0.9489399790763855,\n",
       "  0.9517800211906433,\n",
       "  0.9543799757957458,\n",
       "  0.9564599990844727,\n",
       "  0.9589200019836426,\n",
       "  0.961080014705658],\n",
       " 'val_loss': [0.39013442397117615,\n",
       "  0.3133118152618408,\n",
       "  0.2684215307235718,\n",
       "  0.24390366673469543,\n",
       "  0.22518061101436615,\n",
       "  0.2127813994884491,\n",
       "  0.19894543290138245,\n",
       "  0.18618716299533844,\n",
       "  0.17541281878948212,\n",
       "  0.1766650676727295,\n",
       "  0.1617565006017685,\n",
       "  0.1528058499097824,\n",
       "  0.14935626089572906,\n",
       "  0.14189903438091278,\n",
       "  0.13688597083091736],\n",
       " 'val_accuracy': [0.899399995803833,\n",
       "  0.9128000140190125,\n",
       "  0.9259999990463257,\n",
       "  0.9318000078201294,\n",
       "  0.9375,\n",
       "  0.9408000111579895,\n",
       "  0.945900022983551,\n",
       "  0.9484999775886536,\n",
       "  0.9527000188827515,\n",
       "  0.95169997215271,\n",
       "  0.9555000066757202,\n",
       "  0.9571999907493591,\n",
       "  0.9585999846458435,\n",
       "  0.9603000283241272,\n",
       "  0.9605000019073486]}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Podemos ver como evoluciona el entrenamiento, en funcion de los epochs\n",
    "# Validacion y training estan muy cerca, no hay overfitting!\n",
    "# Todavia no ha acabado de coverger ya que el loss en validacion sigue bajando,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0957 - accuracy: 0.9708\n",
      "test loss, test acc: [0.0956917330622673, 0.97079998254776]\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el \"score\" a partir del conjunto de test\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "\n",
    "\n",
    "# Metodo evaluate para que nos de el error vs las metricas elegidas en la funcion compile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 184ms/step\n",
      "predictions shape: (1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.002, 0.   , 0.   , 0.   , 0.998, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Ojo aqui viene slicing xq presupone que le entran varios inputs\n",
    "Nos da las probabilidades de pertenecer a una clase u otra.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 3s 5ms/step - loss: 0.9142 - val_loss: 0.6022\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5061 - val_loss: 0.5870\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4697 - val_loss: 0.5118\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4520 - val_loss: 0.5039\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4410 - val_loss: 0.4765\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4318 - val_loss: 0.4693\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4319 - val_loss: 0.4602\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4180 - val_loss: 0.4577\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4242 - val_loss: 0.4615\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4182 - val_loss: 0.4444\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4111 - val_loss: 0.4433\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4022 - val_loss: 0.4323\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3958 - val_loss: 0.4253\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3942 - val_loss: 0.4223\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3902 - val_loss: 0.4253\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3860 - val_loss: 0.4157\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3824 - val_loss: 0.4156\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3806 - val_loss: 0.4120\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3793 - val_loss: 0.4144\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3780 - val_loss: 0.4043\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3809\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000220B764E700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 516ms/step\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Sirven para que el modelo se vaya guardando tras cada epoch, asi no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 3s 5ms/step - loss: 0.3728\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3719\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3683\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3670\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3649\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3611\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3594\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3624\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3665\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3613\n",
      "Epoch 1/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3534 - val_loss: 0.3775\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3534 - val_loss: 0.3765\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3497 - val_loss: 0.3806\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3477 - val_loss: 0.3991\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3446 - val_loss: 0.3747\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3423 - val_loss: 0.3677\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3424 - val_loss: 0.3672\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3415 - val_loss: 0.3641\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3378 - val_loss: 0.3638\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3384 - val_loss: 0.3633\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3372 - val_loss: 0.3592\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3340 - val_loss: 0.3637\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3355 - val_loss: 0.3556\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3317 - val_loss: 0.3578\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3303 - val_loss: 0.5140\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3315 - val_loss: 0.3605\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3416 - val_loss: 0.3847\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3311 - val_loss: 0.3527\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3301 - val_loss: 0.3553\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3305 - val_loss: 0.3533\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3276 - val_loss: 0.3520\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3394 - val_loss: 0.3691\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3236 - val_loss: 0.4377\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3317 - val_loss: 0.3622\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3311 - val_loss: 0.3538\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3251 - val_loss: 0.3541\n"
     ]
    }
   ],
   "source": [
    "# 10 esta bien. Lo pondemos a 5 para el ejercicio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard\n",
    "Keras tiene implementado un dashboard para monitorizar las ejecuciones del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3267 - val_loss: 0.3540\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3260 - val_loss: 0.3719\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3248 - val_loss: 0.3584\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3305 - val_loss: 0.3463\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3224 - val_loss: 0.3525\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3216 - val_loss: 0.3499\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3209 - val_loss: 0.3574\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3234 - val_loss: 0.3808\n",
      "Epoch 9/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3234 - val_loss: 0.3478\n",
      "Epoch 10/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3219 - val_loss: 0.8798\n",
      "Epoch 11/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3307 - val_loss: 0.3631\n",
      "Epoch 12/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3182 - val_loss: 0.3607\n",
      "Epoch 13/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3189 - val_loss: 0.3450\n",
      "Epoch 14/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3167 - val_loss: 0.3470\n",
      "Epoch 15/50\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3230 - val_loss: 0.4674\n",
      "Epoch 16/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3322 - val_loss: 0.3491\n",
      "Epoch 17/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3202 - val_loss: 0.3462\n",
      "Epoch 18/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3155 - val_loss: 0.3491\n",
      "Epoch 19/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3182 - val_loss: 0.3556\n",
      "Epoch 20/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3166 - val_loss: 0.3470\n",
      "Epoch 21/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3174 - val_loss: 0.3424\n",
      "Epoch 22/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3162 - val_loss: 0.4015\n",
      "Epoch 23/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3143 - val_loss: 0.3512\n",
      "Epoch 24/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3156 - val_loss: 0.3600\n",
      "Epoch 25/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3199 - val_loss: 1.2894\n",
      "Epoch 26/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3539 - val_loss: 0.3634\n",
      "Epoch 27/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3133 - val_loss: 0.3595\n",
      "Epoch 28/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3156 - val_loss: 0.3872\n",
      "Epoch 29/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3133 - val_loss: 0.3480\n",
      "Epoch 30/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3151 - val_loss: 0.3509\n",
      "Epoch 31/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3338 - val_loss: 0.3492\n",
      "Epoch 32/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3125 - val_loss: 0.3476\n",
      "Epoch 33/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3932 - val_loss: 0.3715\n",
      "Epoch 34/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3195 - val_loss: 0.3515\n",
      "Epoch 35/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3170 - val_loss: 0.4182\n",
      "Epoch 36/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3152 - val_loss: 0.3779\n",
      "Epoch 37/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3176 - val_loss: 0.3421\n",
      "Epoch 38/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3130 - val_loss: 0.3486\n",
      "Epoch 39/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3124 - val_loss: 0.4086\n",
      "Epoch 40/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3166 - val_loss: 0.3559\n",
      "Epoch 41/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3165 - val_loss: 0.3477\n",
      "Epoch 42/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3202 - val_loss: 0.3585\n",
      "Epoch 43/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3102 - val_loss: 0.3396\n",
      "Epoch 44/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3134 - val_loss: 0.3484\n",
      "Epoch 45/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3120 - val_loss: 0.3595\n",
      "Epoch 46/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3141 - val_loss: 0.3360\n",
      "Epoch 47/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3088 - val_loss: 0.3429\n",
      "Epoch 48/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3111 - val_loss: 0.3335\n",
      "Epoch 49/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3135 - val_loss: 0.3612\n",
      "Epoch 50/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3111 - val_loss: 0.3453\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPara lanzarlo desde el jupyter notebook\\n%load_ext tensorboard\\n%tensorboard --logdir=./my_logs --port=6006\\n\\nPara lanzarlo desde el terminal, hay que estar en la carpeta de los logs\\ntensorboard --logdir=./my_logs --port=6006\\n\\n'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 19596), started 3 days, 11:47:51 ago. (Use '!kill 19596' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f5ad04d628d188c9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f5ad04d628d188c9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
